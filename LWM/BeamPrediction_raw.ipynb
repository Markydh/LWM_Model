{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_18_denver/BS3_UE_0-6970.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6970/6970 [00:00<00:00, 443609.34it/s]\n",
      "Generating channels: 100%|██████████| 6970/6970 [00:00<00:00, 51596.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_15_indianapolis/BS3_UE_0-6320.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6320/6320 [00:00<00:00, 237556.69it/s]\n",
      "Generating channels: 100%|██████████| 6320/6320 [00:00<00:00, 19776.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_19_oklahoma/BS1_UE_0-6150.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6150/6150 [00:00<00:00, 204726.86it/s]\n",
      "Generating channels: 100%|██████████| 6150/6150 [00:00<00:00, 17298.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_12_fortworth/BS1_UE_0-6192.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6192/6192 [00:00<00:00, 318910.70it/s]\n",
      "Generating channels: 100%|██████████| 6192/6192 [00:00<00:00, 34778.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_11_santaclara/BS1_UE_0-5358.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 5358/5358 [00:00<00:00, 210487.14it/s]\n",
      "Generating channels: 100%|██████████| 5358/5358 [00:00<00:00, 21018.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_7_sandiego/BS1_UE_0-5893.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 5893/5893 [00:00<00:00, 264758.22it/s]\n",
      "Generating channels: 100%|██████████| 5893/5893 [00:00<00:00, 25056.32it/s]\n",
      "Processing items: 100%|██████████| 14840/14840 [00:00<00:00, 41997.69it/s]\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_Model/LWM/lwm_model.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the LWM model on cpu...\n",
      "Model loaded successfully from /Users/dianhongyang/Desktop/毕业设计/LWM_Model/LWM/model_weights.pth to cpu\n",
      "torch.Size([14840, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "from input_preprocess import tokenizer\n",
    "from lwm_model import lwm\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from input_preprocess import create_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "\n",
    "# 选择数据集\n",
    "scenario_names = np.array([\n",
    "    \"city_18_denver\", \"city_15_indianapolis\", \"city_19_oklahoma\",\n",
    "    \"city_12_fortworth\", \"city_11_santaclara\", \"city_7_sandiego\"\n",
    "])\n",
    "scenario_idxs = np.array([0, 1, 2, 3, 4, 5])  # Select the scenario indexes\n",
    "selected_scenario_names = scenario_names[scenario_idxs]\n",
    "\n",
    "# 对数据进行标记\n",
    "preprocessed_chs = tokenizer(\n",
    "    selected_scenario_names=selected_scenario_names,  # Selects predefined DeepMIMOv3 scenarios_test. Set to None to load your own dataset.\n",
    "    manual_data=None,  # If using a custom dataset, ensure it is a wireless channel dataset of size (N,32,32) based on the settings provided above.\n",
    "    gen_raw=True  # Set gen_raw=False to apply masked channel modeling (MCM), as used in LWM pre-training. For inference, masking is unnecessary unless you want to evaluate LWM's ability to handle noisy inputs.\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "# 这里应为mps加速和cuda加速存在兼容问题(float类型不兼容)，所以在这里无法使用mps\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Loading the LWM model on {device}...\")\n",
    "model = lwm.from_pretrained(device=device)\n",
    "\n",
    "# 进行推理\n",
    "from inference import lwm_inference, create_raw_dataset\n",
    "input_types = ['cls_emb', 'channel_emb', 'raw']\n",
    "selected_input_type = input_types[2]  # Change the index to select LWM CLS embeddings, LWM channel embeddings, or the original input channels.\n",
    "\n",
    "if selected_input_type in ['cls_emb', 'channel_emb']:\n",
    "    dataset = lwm_inference(preprocessed_chs, selected_input_type, model, device)\n",
    "else:\n",
    "    dataset = create_raw_dataset(preprocessed_chs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14840, 128, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_18_denver/BS3_UE_0-6970.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6970/6970 [00:00<00:00, 463889.22it/s]\n",
      "Generating channels: 100%|██████████| 6970/6970 [00:00<00:00, 56567.92it/s]\n",
      "Computing the channel for each user: 100%|██████████| 6970/6970 [00:00<00:00, 234410.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_15_indianapolis/BS3_UE_0-6320.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6320/6320 [00:00<00:00, 220955.25it/s]\n",
      "Generating channels: 100%|██████████| 6320/6320 [00:00<00:00, 19360.85it/s]\n",
      "Computing the channel for each user: 100%|██████████| 6320/6320 [00:00<00:00, 111279.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_19_oklahoma/BS1_UE_0-6150.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6150/6150 [00:00<00:00, 194239.23it/s]\n",
      "Generating channels: 100%|██████████| 6150/6150 [00:00<00:00, 16862.01it/s]\n",
      "Computing the channel for each user: 100%|██████████| 6150/6150 [00:00<00:00, 112563.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_12_fortworth/BS1_UE_0-6192.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 6192/6192 [00:00<00:00, 326684.99it/s]\n",
      "Generating channels: 100%|██████████| 6192/6192 [00:00<00:00, 33957.62it/s]\n",
      "Computing the channel for each user: 100%|██████████| 6192/6192 [00:00<00:00, 195226.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_11_santaclara/BS1_UE_0-5358.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 5358/5358 [00:00<00:00, 261160.02it/s]\n",
      "Generating channels: 100%|██████████| 5358/5358 [00:00<00:00, 21021.41it/s]\n",
      "Computing the channel for each user: 100%|██████████| 5358/5358 [00:00<00:00, 121664.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n",
      "/Users/dianhongyang/Desktop/毕业设计/LWM_MODEL/LWM/scenarios/city_7_sandiego/BS1_UE_0-5893.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 5893/5893 [00:00<00:00, 275810.50it/s]\n",
      "Generating channels: 100%|██████████| 5893/5893 [00:00<00:00, 24167.80it/s]\n",
      "Computing the channel for each user: 100%|██████████| 5893/5893 [00:00<00:00, 160418.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#获得labels\n",
    "tasks = ['LoS/NLoS Classification', 'Beam Prediction']\n",
    "task = tasks[1] # Choose 0 for LoS/NLoS labels or 1 for beam prediction labels.\n",
    "labels = create_labels(task, scenario_names, n_beams=16) # For beam prediction, n_beams specifies the number of beams in the codebook. If you're generating labels for LoS/NLoS classification, you can leave this value unchanged as it doesn't impact the label generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2375, 128, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个信道是128 * 16的矩阵\n",
    "# 可以使用卷积神经网络处理\n",
    "# 数据划分\n",
    "# 1. 信道数据\n",
    "\n",
    "# 初始数据划分\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# 二次划分：将训练集划分为训练集和验证集，比例为8:2\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "x_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "# 假设 x_train, x_val, x_test 是 Tensor，形状为 (num_samples, num_patches, patch_dim)\n",
    "x_train_np = x_train.reshape(-1, x_train.shape[-1]).numpy()  # 形状变为 (num_samples * num_patches, patch_dim)\n",
    "x_val_np = x_val.reshape(-1, x_val.shape[-1]).numpy()\n",
    "x_test_np = x_test.reshape(-1, x_test.shape[-1]).numpy()\n",
    "\n",
    "# 使用 StandardScaler 对所有补丁的特征进行归一化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_np)  # 只用训练集的统计信息\n",
    "x_train_scaled = scaler.transform(x_train_np).reshape(x_train.shape)  # 还原为 (num_samples, num_patches, patch_dim)\n",
    "x_val_scaled = scaler.transform(x_val_np).reshape(x_val.shape)\n",
    "x_test_scaled = scaler.transform(x_test_np).reshape(x_test.shape)\n",
    "\n",
    "# 转换回 Tensor\n",
    "x_train = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "x_val = torch.tensor(x_val_scaled, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
    "\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 9497\n",
      "验证集大小: 2375\n",
      "测试集大小: 2968\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# 定义 DataLoader\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 可选：查看各部分数据的大小\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerClassifier(\n",
      "  (embedding): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, patch_dim, num_patches, num_classes, embed_dim=64, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        # 补丁嵌入层\n",
    "        self.embedding = nn.Linear(patch_dim, embed_dim)  # 将每个补丁从 patch_dim 映射到 embed_dim\n",
    "        \n",
    "        # Transformer 编码器层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,  # 输入的维度\n",
    "            nhead=num_heads,    # 多头注意力的头数\n",
    "            dim_feedforward=embed_dim * 4,  # 前馈网络的维度\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 分类头\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, num_patches, patch_dim)\n",
    "        x = self.embedding(x)   # 映射到 (batch_size, num_patches, embed_dim)\n",
    "        x = x.permute(1, 0, 2)  # 转置为 (num_patches, batch_size, embed_dim)\n",
    "        x = self.encoder(x)     # Transformer 编码器\n",
    "        x = x.mean(dim=0)       # 对序列（补丁）取平均，得到 (batch_size, embed_dim)\n",
    "        x = self.fc(x)          # 分类层\n",
    "        return x\n",
    "\n",
    "# 模型初始化\n",
    "patch_dim = 16  # 每个补丁的维度\n",
    "num_patches = 128  # 补丁的数量\n",
    "num_classes = 16  # 分类的类别数\n",
    "model = TransformerClassifier(patch_dim, num_patches, num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 195.7344, Accuracy: 0.1696\n",
      "Accuracy: 0.1848  F1-Score: 0.1014\n",
      "Epoch 2/200, Loss: 192.6241, Accuracy: 0.1775\n",
      "Accuracy: 0.1789  F1-Score: 0.0856\n",
      "Epoch 3/200, Loss: 191.1192, Accuracy: 0.1872\n",
      "Accuracy: 0.1836  F1-Score: 0.0787\n",
      "Epoch 4/200, Loss: 189.7248, Accuracy: 0.1884\n",
      "Accuracy: 0.1794  F1-Score: 0.0998\n",
      "Epoch 5/200, Loss: 185.8332, Accuracy: 0.2006\n",
      "Accuracy: 0.1933  F1-Score: 0.1052\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m batch_y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义训练参数\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)  # 前向传播\n",
    "        loss = criterion(outputs, batch_y)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += (preds == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # 验证集评估\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    # 计算验证集指标\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {val_accuracy:.4f}  F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "# 训练集评估\n",
    "train_preds = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# 计算训练集指标\n",
    "train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "train_f1 = f1_score(train_labels, train_preds, average=\"weighted\")\n",
    "train_recall = recall_score(train_labels, train_preds, average=\"weighted\")\n",
    "train_conf_matrix = confusion_matrix(train_labels, train_preds)\n",
    "\n",
    "print(\"\\nTraining Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"F1-Score: {train_f1:.4f}\")\n",
    "print(f\"Recall: {train_recall:.4f}\")\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(train_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Training Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
